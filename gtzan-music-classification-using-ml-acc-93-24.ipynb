{"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1032238,"sourceType":"datasetVersion","datasetId":568973}],"dockerImageVersionId":30698,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <div style=\"height: 8px; background: linear-gradient(to right, orange, red); border-radius: 4px;\"></div>\n\n# Music Genre Classification using Machine Learning\n-------------------------------------------------\n\n### Introduction\n\nMusic genre classification is of great importance in the field of machine learning. It enables various applications such as personalized recommendations, music organization, content licensing, and music analysis. In this notebook, my goal is to leverage different ML methods to automatically classify 10 distinct music genres using the GTZAN dataset. The dataset consists of 10 genres, each containing 100 music samples.\n\nGenres included in the dataset:\n- Blues\n- Classical\n- Country\n- Disco\n- Hip Hop\n- Jazz\n- Metal\n- Pop\n- Reggae\n- Rock\n\n### Dataset Source\n\nThe GTZAN dataset can be accessed through the following link on Kaggle: [GTZAN Dataset - Music Genre Classification](https://www.kaggle.com/datasets/andradaolteanu/gtzan-dataset-music-genre-classification)\n\n### Objective\n\nThe primary objective of this notebook is to explore and apply various ML methods for the automatic classification of music genres. By implementing feature engineering, model training, and evaluation techniques, I aim to develop accurate and efficient classifiers capable of identifying the genre of a given music sample.\n\n### Implementation\n\nThroughout this notebook, I will employ a range of ML algorithms and techniques such as data preprocessing, feature extraction, model selection, and evaluation. By experimenting with different approaches, I seek to identify the most effective methods for achieving high classification accuracy and robustness in music genre classification tasks.\n\nLet's dive in and explore the fascinating world of music genre classification!","metadata":{}},{"cell_type":"code","source":"# Install the Librosa library\n# Librosa is used for music and audio analysis. It provides the tools necessary for music genre classification,\n# including audio feature extraction such as Mel-frequency cepstral coefficients (MFCCs), spectral contrast, \n# and zero-crossing rate. This will help in accurately classifying different genres based on their audio patterns.\n\n!pip install librosa","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Standard library imports\nimport warnings\n\n# Third-party imports for data manipulation and analysis\nimport numpy as np\nimport pandas as pd\n\n# Visualization libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Audio processing library\nimport librosa\nimport librosa.display\n\n# Machine learning preprocessing and model selection\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler, minmax_scale\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\n\n# Deep learning libraries\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nfrom keras.optimizers import Adam\n\n# Statistical distributions for randomized search\nfrom scipy.stats import loguniform, randint\n\n# Suppress warnings\nwith warnings.catch_warnings():\n    warnings.simplefilter(\"ignore\")\n\n# Set up the aesthetics for seaborn plots\nsns.set(style=\"whitegrid\")\n\n# Ensure that plots are displayed in the Jupyter Notebook\n%matplotlib inline","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"height: 8px; background: linear-gradient(to right, orange, red); border-radius: 4px;\"></div>\n\n## Exploring a Sample from the GTZAN Dataset\n\nI start by examining the first sample from the pop music category within the GTZAN Music dataset. \n\nFor further analysis, the complete dataset, which includes tracks from 10 different genres, is available on Kaggle:\n[GTZAN Dataset - Music Genre Classification](https://www.kaggle.com/datasets/andradaolteanu/gtzan-dataset-music-genre-classification)","metadata":{}},{"cell_type":"code","source":"audio_path = 'C:\\\\Users\\\\admin\\\\Desktop\\\\MLPracticing\\\\music_genre_classificaion\\\\pop.00000.wav'\naudio, sr = librosa.load(audio_path)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"height: 8px; background: linear-gradient(to right, orange, red); border-radius: 4px;\"></div>\n\n## Visualizing Audio Data: Waveform Plot of a Pop Music Sample\n\nThe GTZAN Music Genre Classification dataset comprises music samples from various genres, each with a uniform duration of 30 seconds. In the analysis below, I visualize waveform of the selected pop music sample to examine its audio characteristics.\n\nIt's crucial to highlight that the dataset also includes a version where each 30-second track is subdivided into ten segments, each lasting 3 seconds. This segmentation approach effectively increases the dataset's volume by providing more samples for training, which can enhance the accuracy of genre classification models by offering more granular data for analysis.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(14, 5))\nlibrosa.display.waveshow(audio, sr=sr)\nplt.xlabel('Time (samples)')\nplt.ylabel('Amplitude')\nplt.title('The first sample track from the pop music folder')\nplt.xlim([0,30])\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"height: 8px; background: linear-gradient(to right, orange, red); border-radius: 4px;\"></div>\n\n## Analyzing Audio Features in the GTZAN Dataset\n\nThe `features_3_sec.csv` file from the [GTZAN Music Genre Classification dataset on Kaggle](https://www.kaggle.com/datasets/andradaolteanu/gtzan-dataset-music-genre-classification) includes several audio features extracted from segmented 3-second clips of music tracks. Each feature provides insights into different aspects of the audio signals. Below, we briefly describe each feature and will later illustrate them using a specific music track from the dataset.\n\n1. **Chroma STFT (Short-Time Fourier Transform)**: Measures the intensity of different pitches in a music track, providing a representation of the audio in terms of its harmonic content across 12 different pitch classes.\n\n2. **RMS (Root Mean Square) Mean**: Indicates the average power or loudness of the audio signal.\n\n3. **Spectral Centroid Mean**: Represents the \"center of mass\" of the spectrum, giving a sense of the brightness of a sound.\n\n4. **Spectral Bandwidth Mean**: Measures the width of the band of light at half the peak maximum and effectively indicates the range of frequencies present in the sound.\n\n5. **Rolloff Mean**: The frequency below which a specified percentage (typically 85% to 95%) of the total spectral energy lies, highlighting the shape of the audio spectrum.\n\n6. **Zero Crossing Rate Mean**: The rate at which the signal changes signs, which can indicate the noisiness or the complexity of a sound.\n\n7. **Harmony Mean**: Extracts the harmonic components of the audio, which are important for the perception of musical notes.\n\n8. **Perceptual Sharpness Mean**: Measures the sharpness or brightness of the audio, which affects how listeners perceive the \"edge\" or clarity of a sound.\n\n9. **Tempo**: The speed at which a piece of music is played, calculated in beats per minute (BPM).\n\n10. **MFCC (Mel Frequency Cepstral Coefficients) Mean**: Describes the overall shape of the spectral envelope and is widely used in audio signal processing and speech recognition for timbre and speech clarity characterization.\n\nIn the following sections, I will visualize each of these features using the pop music track previously mentioned to better understand how they represent different aspects of the music.","metadata":{}},{"cell_type":"markdown","source":"<div style=\"height: 8px; background: linear-gradient(to right, orange, red); border-radius: 4px;\"></div>\n\n## Chroma STFT\n\nChroma STFT (Short-Time Fourier Transform) is a feature representation used to capture the pitch content of an audio signal. This process involves mapping the audio onto a 12-dimensional chroma space, which corresponds to the 12 pitch classes commonly found in Western music.\n\nThe computation of Chroma STFT begins with the application of the Short-Time Fourier Transform (STFT) to the audio signal. STFT analyzes the spectral content over time by breaking the signal into short segments and computing the Fourier Transform separately on each segment. This provides a time-varying spectral representation.\n\nFollowing the STFT, the spectral information is aggregated into chroma features. These chroma features summarize the entire spectrum by focusing on the 12 different pitch classes, effectively reducing the complexity of the data while retaining essential information about the pitch content. This makes Chroma STFT particularly useful for tasks that involve recognizing musical notes or chords, regardless of the specific octaves in which they occur.","metadata":{}},{"cell_type":"code","source":"chroma_stft = librosa.feature.chroma_stft(y=audio, sr=sr)\n\nplt.figure(figsize=(14, 5))\nlibrosa.display.specshow(chroma_stft, x_axis='time', y_axis='chroma', sr=sr)\nplt.colorbar()\nplt.xlabel('Time (s)')\nplt.ylabel('Pitch Class')\nplt.title('Chroma STFT')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"height: 8px; background: linear-gradient(to right, orange, red); border-radius: 4px;\"></div>\n\n## RMS Mean\n\nRMS Mean, or Root Mean Square Mean, is a key audio feature that represents the average energy or amplitude of an audio signal over time. It serves as a summary measure of the overall loudness or intensity of the audio.\n\nThe computation of RMS Mean involves several steps:\n1. **Calculating the RMS for each time frame**: The RMS value for a given time frame is calculated by taking the square root of the average of the squares of the sample amplitudes within that frame. This method ensures that all amplitude values are non-negative, providing a true measure of the signal's power.\n2. **Averaging RMS values**: Once the RMS values are calculated for each time frame, the RMS Mean is obtained by averaging these values. This average provides a consistent measure of the audio signal's loudness across its entire duration.\n\nBy quantifying the signal's loudness, the RMS Mean is particularly useful in applications where audio levels need to be normalized or compared across different recordings.","metadata":{}},{"cell_type":"code","source":"rms = librosa.feature.rms(y=audio)\nrms_mean = rms.mean()\n\nprint(\"RMS Mean:\", rms_mean)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"height: 8px; background: linear-gradient(to right, orange, red); border-radius: 4px;\"></div>\n\n## Spectral Centroid Mean\n\nThe Spectral Centroid Mean is a crucial audio feature that represents the average \"center of mass\" of the spectrum of an audio signal over time. It effectively measures the weighted mean of the frequencies present in the signal, where their magnitudes serve as the weights. This feature is computed as the mean of the spectral centroid values across different time frames.\n\n### Importance\nThe Spectral Centroid Mean provides a summary measure of the overall tonal character or spectral brightness of the audio signal. A higher spectral centroid indicates a sound that is perceived as \"brighter\" or having more high frequencies, while a lower centroid suggests a \"darker\" sound with more low frequencies.\n\n","metadata":{}},{"cell_type":"code","source":"spectral_centroids = librosa.feature.spectral_centroid(y=audio, sr=sr)\nspectral_centroids_mean = spectral_centroids.mean()\n\nprint(\"Spectral Centroid Mean:\", spectral_centroids_mean)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate the spectral centroids\nspectral_centroids = librosa.feature.spectral_centroid(y=audio, sr=sr)\n\n# Computing the time variable for visualization\nframes = range(len(spectral_centroids[0]))\nt = librosa.frames_to_time(frames, sr=sr)\n\n# Function that normalizes the Sound Data\ndef normalize(x, axis=0):\n    return minmax_scale(x, axis=axis)\n\n# Use a stylish plot theme\nplt.style.use('seaborn-dark-palette')\n\n# Plotting the Spectral Centroid along the waveform\nplt.figure(figsize=(16, 6))\nax = plt.axes()\nax.set_facecolor('#202020')  # Set a dark background color\n\n# Waveform plot\nlibrosa.display.waveshow(audio, sr=sr, alpha=0.6, color='#1DB954', linewidth=1.5, label='Waveform')\n\n# Spectral centroids plot\nplt.plot(t, normalize(spectral_centroids[0]), color='#FFC300', linewidth=2, label='Normalized Spectral Centroids')\n\n# Enhancing the plot\nplt.title('Waveform and Normalized Spectral Centroids', fontsize=16, fontweight='bold', color='white')\nplt.xlabel('Time (seconds)', fontsize=14, color='white')\nplt.ylabel('Normalized Amplitude / Frequency', fontsize=14, color='white')\nplt.legend()\nplt.grid(True, linestyle='--', linewidth=0.5)\nplt.xticks(fontsize=12, color='white')\nplt.yticks(fontsize=12, color='white')\n\n# Show the plot\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"height: 8px; background: linear-gradient(to right, orange, red); border-radius: 4px;\"></div>\n\n# Spectral Bandwidth Mean\n\nSpectral Bandwidth Mean is an analytical metric that represents the average value of the spectral bandwidth of an audio signal over time. This metric quantifies the mean spread or width of the frequencies in the signal's spectrum.\n\n### Importance \n\nSpectral Bandwidth provides crucial information about the spectral complexity or variation in frequency content of the audio signal. Essentially, it measures how much the energy of a signal is spread across different frequencies. A larger bandwidth indicates a broader spread of frequencies, suggesting a more complex sound, while a narrower bandwidth suggests a purer tone with fewer frequency components.\n\n\n","metadata":{}},{"cell_type":"code","source":"spectral_bandwidths = librosa.feature.spectral_bandwidth(y=audio, sr=sr)\nspectral_bandwidths_mean = spectral_bandwidths.mean()\n\nprint(\"Spectral Bandwidth Mean:\", spectral_bandwidths_mean)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"height: 8px; background: linear-gradient(to right, orange, red); border-radius: 4px;\"></div>\n\n# Spectral Rolloff Mean\n\nSpectral Rolloff Mean is a significant audio feature that represents the average frequency below which a specified percentage of the total spectral energy of an audio signal is concentrated. This metric provides a summary measure of the overall high-frequency content or cutoff frequency of the audio signal's spectrum.\n\n## Significance of Spectral Rolloff\n\nThe spectral rolloff point is an important descriptor in audio signal processing as it effectively captures the boundary of the higher frequencies in an audio spectrum. A lower rolloff point indicates that most of the energy is concentrated in the lower frequencies, while a higher rolloff point suggests a presence of substantial high-frequency energy, potentially indicating brightness or sharpness in the sound.\n","metadata":{}},{"cell_type":"code","source":"spectral_rolloff = librosa.feature.spectral_rolloff(y=audio, sr=sr)\nspectral_rolloff_mean = spectral_rolloff.mean()\n\nprint(\"Spectral Rolloff Mean:\", spectral_rolloff_mean)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Computing the time variable for visualization\nframes = range(len(spectral_rolloff [0]))\nt = librosa.frames_to_time(frames, sr=sr)\n\n# Function that normalizes the Sound Data\ndef normalize(x, axis=0):\n    return minmax_scale(x, axis=axis)\n\n# Use a stylish plot theme\nplt.style.use('seaborn-dark-palette')\n\n# Plotting the spectral_rolloff along the waveform\nplt.figure(figsize=(16, 6))\nax = plt.axes()\nax.set_facecolor('#202020')  # Set a dark background color\n\n# Waveform plot\nlibrosa.display.waveshow(audio, sr=sr, alpha=0.6, color='#1DB954', linewidth=1.5, label='Waveform')\n\n# chroma_cens plot\nplt.plot(t, normalize(spectral_rolloff[0]), color='#FFC300', linewidth=2, label='Normalized spectral_rolloff')\n\n# Enhancing the plot\nplt.title('Waveform and Normalized spectral_rolloff', fontsize=16, fontweight='bold', color='white')\nplt.xlabel('Time (seconds)', fontsize=14, color='white')\nplt.ylabel('Normalized Amplitude / Frequency', fontsize=14, color='white')\nplt.legend()\nplt.grid(True, linestyle='--', linewidth=0.5)\nplt.xticks(fontsize=12, color='white')\nplt.yticks(fontsize=12, color='white')\n\n# Show the plot\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"height: 8px; background: linear-gradient(to right, orange, red); border-radius: 4px;\"></div>\n\n# Zero-Crossing Rate Mean\n\nThe Zero-Crossing Rate Mean is a fundamental audio analysis metric that represents the average rate at which an audio signal crosses the zero axis over time. This measure provides a valuable insight into the temporal variations or the frequency of rapid changes in the audio signal.\n\n## Understanding Zero-Crossing Rate\n\nZero-crossing rate is a critical parameter in digital signal processing that quantifies how frequently the amplitude of the audio waveform crosses the zero value. This rate is particularly indicative of the noise level and timbral characteristics of the signal. High zero-crossing rates are often associated with noisy or complex sounds, while low rates typically indicate tonal or harmonic sounds.\n","metadata":{}},{"cell_type":"code","source":"zero_crossing_rates = librosa.feature.zero_crossing_rate(y=audio)\nzero_crossing_rates_mean = zero_crossing_rates.mean()\n\nprint(\"Zero-Crossing Rate Mean:\", zero_crossing_rates_mean)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"height: 8px; background: linear-gradient(to right, orange, red); border-radius: 4px;\"></div>\n\n# Harmony Mean\n\nThe Harmony Mean is a quantifiable audio feature that represents the average level of harmony or consonance in an audio signal over time. This metric provides a summary measure of the overall harmonic content and musical tonality, offering insights into the structural and aesthetic qualities of music and sound.\n\n## Significance of Harmony in Audio Analysis\n\nHarmony, in the context of music and audio, refers to the simultaneous combination of tones, especially when blended into chords that are pleasing to the ear. Consonance, or the degree of harmony, is crucial for understanding the musicality and mood conveyed by an audio signal. A higher harmony mean suggests a richer and more consonant harmonic structure, which is typical in melodious and harmonically complex music. Conversely, a lower harmony mean might indicate dissonance, tension, or a more percussive and rhythmic nature of the sound.\n\n","metadata":{}},{"cell_type":"code","source":"chroma_cens = librosa.feature.chroma_cens(y=audio, sr=sr)\nharmony_mean = chroma_cens.mean()\n\nprint(\"Harmony Mean:\", harmony_mean)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Computing the time variable for visualization\nframes = range(len(chroma_cens[0]))\nt = librosa.frames_to_time(frames, sr=sr)\n\n# Function that normalizes the Sound Data\ndef normalize(x, axis=0):\n    return minmax_scale(x, axis=axis)\n\n# Use a stylish plot theme\nplt.style.use('seaborn-dark-palette')\n\n# Plotting the Spectral Centroid along the waveform\nplt.figure(figsize=(16, 6))\nax = plt.axes()\nax.set_facecolor('#202020')  # Set a dark background color\n\n# Waveform plot\nlibrosa.display.waveshow(audio, sr=sr, alpha=0.6, color='#1DB954', linewidth=1.5, label='Waveform')\n\n# chroma_cens plot\nplt.plot(t, normalize(chroma_cens[0]), color='#FFC300', linewidth=2, label='Normalized chroma_cens')\n\n# Enhancing the plot\nplt.title('Waveform and Normalized chroma_cens', fontsize=16, fontweight='bold', color='white')\nplt.xlabel('Time (seconds)', fontsize=14, color='white')\nplt.ylabel('Normalized Amplitude / Frequency', fontsize=14, color='white')\nplt.legend()\nplt.grid(True, linestyle='--', linewidth=0.5)\nplt.xticks(fontsize=12, color='white')\nplt.yticks(fontsize=12, color='white')\n\n# Show the plot\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n<div style=\"height: 8px; background: linear-gradient(to right, orange, red); border-radius: 4px;\"></div>\n\n# Tempo Mean\n\nThe Tempo Mean is a single scalar value that quantifies the average perceived tempo, measured in beats per minute (BPM), of an audio signal over time. This metric offers a summary measure of the overall tempo or rhythmic characteristics of the audio signal, providing insights into its rhythmic pace and consistency.\n\n## Importance of Tempo in Audio Analysis\n\nTempo is a fundamental aspect of music and audio that relates to the speed or pace at which the piece is played. It is crucial for determining the mood and style of the music, influencing how listeners perceive and react to the sound. A faster tempo typically conveys energy and excitement, while a slower tempo might evoke calmness or solemnity.\n\n","metadata":{}},{"cell_type":"code","source":"tempo, _ = librosa.beat.beat_track(y=audio, sr=sr)\ntempo_mean = tempo.mean()\n\nprint(\"Tempo Mean (BPM):\", tempo_mean)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n<div style=\"height: 8px; background: linear-gradient(to right, orange, red); border-radius: 4px;\"></div>\n\n# Mel Frequency Cepstral Coefficients (MFCC)\n\nMel Frequency Cepstral Coefficients (MFCC) are a feature commonly used in audio signal processing, particularly in the areas of speech recognition and music analysis. These coefficients effectively represent the short-term power spectrum of an audio signal, derived through a linear cosine transform of a log power spectrum on a nonlinear mel scale of frequency.\n\n## Importance of MFCC in Audio Analysis\n\nMFCCs are crucial because they closely approximate the human auditory system's response and are robust for voice identification, even in noisy environments. Their ability to capture important spectral properties makes them highly effective for various tasks in audio analysis, including speaker identification, speech recognition, and music genre classification.\n\n","metadata":{}},{"cell_type":"code","source":"# Compute MFCCs\nmfccs = librosa.feature.mfcc(y=audio, sr=sr)\n\n# Apply Feature Scaling\nmfccs = sklearn.preprocessing.scale(mfccs, axis=1)\n\n# Plot MFCCs\nplt.figure(figsize=(10, 4))\nlibrosa.display.specshow(mfccs, x_axis='time', cmap='coolwarm')\nplt.colorbar(format='%+2.0f dB')\nplt.title('MFCC')\nplt.xlabel('Time')\nplt.ylabel('MFCC Coefficients')\nplt.tight_layout()\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n<div style=\"height: 8px; background: linear-gradient(to right, orange, red); border-radius: 4px;\"></div>\n\n\n# Loading the Data\n\nIn this initial step, I loaded the feature matrix from features_3_sec.csv into a pandas DataFrame. This dataset comprises a comprehensive matrix with dimensions indicating it contains 9990 entries, each characterized by 60 distinct features.\n","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('C:/Users/admin/Desktop/MLPracticing/music_genre_classificaion/features_3_sec.csv')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.iloc[1,:]   # here, the name of the features has been listed","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's see is there any NaN value in different columns of the dataframe üßê","metadata":{}},{"cell_type":"code","source":"df.isna().sum() ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"it seems that there is no NaN at all üòä","metadata":{}},{"cell_type":"markdown","source":"I have removed the initial column, 'filename', from the DataFrame, as it does not influence the classification results.","metadata":{}},{"cell_type":"code","source":"df = df.drop('filename', axis = 1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n<div style=\"height: 8px; background: linear-gradient(to right, orange, red); border-radius: 4px;\"></div>\n\n## Exploratory Data Analysis (EDA)\n\n### Correlation Heatmap\n\nThe correlation heatmap displayed below offers a visual representation of the relationships between features. It serves as a valuable tool for identifying which features are most closely related to each other. This insight can assist in understanding feature dependencies, which may influence subsequent modeling decisions.","metadata":{}},{"cell_type":"code","source":"mean_columns = df.filter(regex='_mean$')\n\ncorrelation_matrix = mean_columns.corr()\n\n# Create a boolean mask for the upper triangle of the matrix\nmask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n\n# Set up the matplotlib figure\nplt.figure(figsize=(12, 10))\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(230, 20, as_cmap=True)\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(correlation_matrix, mask=mask, cmap=cmap, annot=False, linewidths=0,\n            cbar_kws={\"shrink\": .5}, square=True)\n\n# Add a title to the heatmap\nplt.title('Correlation Heatmap of Mean Features', fontsize=16, fontweight='bold')\n\n# Show the plot\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Box Plot for Genres Distributions","metadata":{}},{"cell_type":"code","source":"# Subset the DataFrame to include only the 'label' and 'tempo' columns\nx = df[[\"label\", \"tempo\"]]\n\n# Create the plot\nf, ax = plt.subplots(figsize=(16, 9))\nsns.boxplot(x=\"label\", y=\"tempo\", data=x, palette='husl')\n\n# Styling the plot with titles and labels\nplt.title('BPM Boxplot for Genres', fontsize=25, fontweight='bold')\nplt.xlabel(\"Genre\", fontsize=15)\nplt.ylabel(\"BPM\", fontsize=15)\n\n# Setting the font size for x and y ticks for better readability\nplt.xticks(fontsize=14)\nplt.yticks(fontsize=14)\n\n# Show the plot\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n<div style=\"height: 8px; background: linear-gradient(to right, orange, red); border-radius: 4px;\"></div>\n\n## Starting with Machine Learning Methods\n\nBefore diving into specific machine learning models, we need to set up our data appropriately:\n\n1. **Define `X` and `y`:**\n   - **`X`** represents our feature matrix, consisting of all columns except the last one.\n   - **`y`** is our target vector, contained in the last column named 'label'.\n\n2. **Split the Data:**\n   - The dataset is divided into 80% for training and 20% for testing. This is a common practice to evaluate the performance of machine learning models on unseen data.\n\nBy preparing the data in this manner, we ensure that we have a solid foundation for applying various machine learning techniques.","metadata":{}},{"cell_type":"code","source":"X = df.iloc[:,:-1]\ny = df.iloc[:,-1]\n\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state = 42)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Encoding Music Genres with LabelEncoder\n\nTo facilitate the application of machine learning algorithms, which typically operate on numeric data, we need to convert the categorical labels in our target column `y` into a numeric format:\n\n- **Using `LabelEncoder`:**\n  - `LabelEncoder` from Scikit-learn is utilized to transform each unique music genre into a specific integer. This encoder assigns a unique integer to each distinct string value in the column.","metadata":{}},{"cell_type":"code","source":"labelencoder = LabelEncoder()\n\ny_train = labelencoder.fit_transform(y_train)\ny_test = labelencoder.transform(y_test)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(labelencoder.classes_)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Scaling with StandardScaler\n\nWhen working with machine learning algorithms, it's important to ensure that the feature data is on a consistent scale. This is especially crucial for algorithms that are sensitive to the magnitude of input features, such as Support Vector Machines (SVM) and k-nearest neighbors (k-NN). Feature scaling helps improve the convergence of steepest descent algorithms, which are commonly used in machine learning optimizations.\n\n### Using `StandardScaler` from Scikit-learn\n\n`StandardScaler` is a preprocessing utility in Scikit-learn that standardizes features by removing the mean and scaling to unit variance. This process, often called Z-score normalization, transforms the features such that they have the properties of a standard normal distribution with a mean of zero and a standard deviation of one.\n\nHere's how to apply `StandardScaler` to our training and testing datasets:","metadata":{}},{"cell_type":"code","source":"scaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n<div style=\"height: 8px; background: linear-gradient(to right, orange, red); border-radius: 4px;\"></div>\n\n## Support Vector Machine (SVM)\n\nSupport Vector Machine (SVM) is a robust and versatile machine learning algorithm used for both classification and regression tasks. It is particularly well-suited for classification of complex but small- or medium-sized datasets. SVM works by finding the hyperplane that best separates the data into classes with the maximum margin. \n\nEffective tuning of SVM hyperparameters is essential to maximize the model's performance. These hyperparameters include the kernel type, the penalty parameter C, and gamma. `GridSearchCV` facilitates this by exhaustively searching through a specified grid of hyperparameter values and determining the combination that yields the best performance through cross-validation. This systematic approach not only enhances the model's accuracy but also its generalizability to new data. I have applied `GridSearchCV` to other machine learning methods as well to ensure optimal performance across different algorithms.","metadata":{}},{"cell_type":"code","source":"# Define the parameter distribution for SVM\nparam_dist_svm = {\n    'C': loguniform(1e-4, 1e+1),  # Narrower range for C\n    'kernel': ['linear', 'rbf'],  # Only linear and RBF kernels\n    # 'gamma': loguniform(1e-4, 1e-3)  # Consider removing if using a linear kernel\n}\n\n# Create the SVM classifier and randomized search object\nsvm = SVC(random_state=42)\nrandom_search_svm = RandomizedSearchCV(\n    svm, param_distributions=param_dist_svm, n_iter=50,  # Reduced number of iterations\n    scoring='accuracy', n_jobs=-1, random_state=42  # Use all available cores\n)\n\n# Fit the randomized search to the data\nrandom_search_svm.fit(X_train, y_train)\n\n# Evaluate the SVM model with the best parameters on the test set\nbest_svm = random_search_svm.best_estimator_\ny_pred_svm = best_svm.predict(X_test)\ntest_accuracy_svm = accuracy_score(y_test, y_pred_svm)\n\n# Evaluate the SVM model on the training set\ny_train_pred_svm = best_svm.predict(X_train)\ntrain_accuracy_svm = accuracy_score(y_train, y_train_pred_svm)\n\nprint(\"Train SVM Accuracy:\", train_accuracy_svm)\nprint(\"Test SVM Accuracy:\", test_accuracy_svm)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"height: 8px; background: linear-gradient(to right, orange, red); border-radius: 4px;\"></div>\n\n## Decision Tree (DT)\n\nDecision Tree (DT) is a popular and intuitive machine learning algorithm used for both classification and regression tasks. It operates by breaking down a dataset into smaller and smaller subsets based on different criteria, effectively building a tree-like model of decisions. Each node in the decision tree represents a feature in the dataset that leads to a decision, and each leaf node represents a class label or a regression outcome. Decision Trees are easy to interpret and visualize, making them an excellent choice for initial data exploration and analysis.","metadata":{}},{"cell_type":"code","source":"# Define the parameter distribution for Decision Tree\nparam_dist_dt = {\n    'max_depth': randint(1, 51),  # Integer range [1, 50]\n    'min_samples_split': randint(2, 11),  # Integer range [2, 10]\n    'min_samples_leaf': randint(1, 11),  # Integer range [1, 10]\n    'criterion': ['gini', 'entropy'],  # Categorical\n    # Consider adding 'max_leaf_nodes': randint(2, 50) for additional pruning\n}\n\n# Create the Decision Tree classifier and randomized search object\ndt = DecisionTreeClassifier(random_state=42)\nrandom_search_dt = RandomizedSearchCV(\n    dt, param_distributions=param_dist_dt, n_iter=50,  # Reduced number of iterations\n    scoring='accuracy', n_jobs=-1, random_state=42  # Use all available cores\n)\n\n# Fit the randomized search to the data\nrandom_search_dt.fit(X_train, y_train)\n\n# Evaluate the Decision Tree model with the best parameters on the test set\nbest_dt = random_search_dt.best_estimator_\ny_pred_dt = best_dt.predict(X_test)\ntest_accuracy_dt = accuracy_score(y_test, y_pred_dt)\n\n# Evaluate the Decision Tree model on the training set\ny_train_pred_dt = best_dt.predict(X_train)\ntrain_accuracy_dt = accuracy_score(y_train, y_train_pred_dt)\n\nprint(\"Train DT Accuracy:\", train_accuracy_dt)\nprint(\"Test DT Accuracy:\", test_accuracy_dt)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"height: 8px; background: linear-gradient(to right, orange, red); border-radius: 4px;\"></div>\n\n## Random Forest (RF)\n\nRandom Forest (RF) is an ensemble learning technique that builds upon the simplicity of decision trees by combining multiple such trees to form a more powerful model. By aggregating the decisions of a multitude of decision trees, each trained on different subsets of the same data, Random Forests reduce the risk of overfitting and typically provide much higher accuracy than individual decision trees. It is highly effective for classification and regression tasks and is known for its performance, ease of use, and versatility.","metadata":{}},{"cell_type":"code","source":"# Define the parameter distribution for Random Forest\nparam_dist_rf = {\n    'n_estimators': randint(10, 101),  # Reduced upper limit for faster computation\n    'max_features': ['auto', 'sqrt'],  # Simplified choice of max features\n    'max_depth': randint(1, 31),  # Controlled tree depth\n    'min_samples_split': randint(2, 11),\n    'min_samples_leaf': randint(1, 11),\n    'bootstrap': [True]  # Consistent use of bootstrapping\n}\n\n# Create the Random Forest classifier and randomized search object\nrf = RandomForestClassifier(random_state=42)\nrandom_search_rf = RandomizedSearchCV(\n    rf, param_distributions=param_dist_rf, n_iter=50,  # Optimized iteration count\n    scoring='accuracy', n_jobs=-1, random_state=42  # Efficient resource usage\n)\n\n# Fit the randomized search to the data\nrandom_search_rf.fit(X_train, y_train)\n\n# Evaluate the Random Forest model with the best parameters on the test set\nbest_rf = random_search_rf.best_estimator_\ny_pred_rf = best_rf.predict(X_test)\ntest_accuracy_rf = accuracy_score(y_test, y_pred_rf)\n\n# Evaluate the Random Forest model on the training set\ny_train_pred_rf = best_rf.predict(X_train)\ntrain_accuracy_rf = accuracy_score(y_train, y_train_pred_rf)\n\nprint(\"Train RF Accuracy:\", train_accuracy_rf)\nprint(\"Test RF Accuracy:\", test_accuracy_rf)","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"height: 8px; background: linear-gradient(to right, orange, red); border-radius: 4px;\"></div>\n\n## K-Nearest Neighbors (KNN)\n\nK-Nearest Neighbors (KNN) is a simple, yet effective machine learning algorithm used primarily for classification, though it can also be used for regression. It classifies a new data point based on the majority vote of its 'k' nearest neighbors, with 'k' being a user-defined constant. KNN is a type of instance-based learning, or lazy learning, where the function is only approximated locally and all computation is deferred until classification. The simplicity of KNN makes it particularly easy to implement and understand, but it becomes significantly slower as the size of data increases.","metadata":{}},{"cell_type":"code","source":"# Define the parameter grid for the random search\nparam_grid = {\n    'n_neighbors': randint(1, 15),  # Number of neighbors\n    'weights': ['uniform', 'distance'],  # Weight function\n    'p': [1, 2]  # Power parameter for the Minkowski distance metric\n}\n\n# Create the KNN classifier\nknn = KNeighborsClassifier()\n\n# Perform the random search\nrandom_search_knn = RandomizedSearchCV(\n    knn, param_distributions=param_grid, n_iter=10, cv=5, random_state=42\n)\nrandom_search_knn.fit(X_train, y_train)\n\n# Evaluate the KNN model with the best parameters on the test set\nbest_knn = random_search_knn.best_estimator_\ny_pred_knn = best_knn.predict(X_test)\ntest_accuracy_knn = accuracy_score(y_test, y_pred_knn)\n\n# Evaluate the KNN model on the training set\ny_train_pred_knn = best_knn.predict(X_train)\ntrain_accuracy_knn = accuracy_score(y_train, y_train_pred_knn)\n\nprint(\"Train KNN Accuracy:\", train_accuracy_knn)\nprint(\"Test KNN Accuracy:\", test_accuracy_knn)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"height: 8px; background: linear-gradient(to right, orange, red); border-radius: 4px;\"></div>\n\n## Artificial Neural Networks (ANN)\n\nArtificial Neural Networks (ANN) are a cornerstone of modern machine learning, inspired by the biological processes of the human brain. ANNs consist of layers of interconnected nodes, or \"neurons,\" each capable of performing simple computations. By processing inputs through multiple layers of these neurons, ANNs can model complex patterns and relationships within data. The adaptability and learning capability of ANNs make them particularly powerful for tackling large-scale and complex problems such as music genre classification.","metadata":{}},{"cell_type":"code","source":"# Define the model architecture\nmodel = Sequential()\nmodel.add(Dense(units=256, activation='relu', input_dim=X_train.shape[1]))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(units=256, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(units=256, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(units=256, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(units=len(np.unique(y_train)), activation='softmax'))  # Adjusted to use np.unique for flexibility\n\n# Compile the model\nmodel.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n# Fit the model\nhistory = model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=1, validation_data=(X_test, y_test))\n\n# Retrieve training and validation accuracy\ntrain_accuracy = history.history['accuracy'][-1]  # Last epoch accuracy\nval_accuracy = history.history['val_accuracy'][-1]  # Last epoch validation accuracy\n\n# Predict on test set\ny_pred = model.predict(X_test)\ny_pred_labels = np.argmax(y_pred, axis=1)\n\n# Calculate test accuracy\ntest_accuracy = accuracy_score(y_test, y_pred_labels)\n\n# Print accuracies\nprint('Training accuracy:', train_accuracy)\nprint('Validation accuracy:', val_accuracy)\nprint('Test accuracy:', test_accuracy)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"height: 8px; background: linear-gradient(to right, orange, red); border-radius: 4px;\"></div>\n\n## Final Results\n\nWith 93.24% test accuracy, The KNN model shows the highest test accuracy and superior generalization compared to other models.\n\n\n\n<table style=\"width:100%; font-size:12px;\">\n  <tr>\n    <th style=\"background-color: #f2f2f2; color: black;\">Model</th>\n    <th style=\"background-color: #f2f2f2; color: black;\">Training Accuracy</th>\n    <th style=\"background-color: #f2f2f2; color: black;\">Test Accuracy</th>\n  </tr>\n  <tr>\n    <td>SVM</td>\n    <td>99.50%</td>\n    <td>93.09%</td>\n  </tr>\n  <tr>\n    <td>Decision Tree</td>\n    <td>95.68%</td>\n    <td>66.77%</td>\n  </tr>\n  <tr>\n    <td>Random Forest</td>\n    <td>99.65%</td>\n    <td>85.09%</td>\n  </tr>\n  <tr style=\"color: white; background-color: #4CAF50;\">\n    <td><strong>KNN</strong></td>\n    <td><strong>99.92%</strong></td>\n    <td><strong>93.24%</strong></td>\n  </tr>\n  <tr>\n    <td>ANN</td>\n    <td>98.59%</td>\n    <td>92.24%</td>\n  </tr>\n</table>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"height: 8px; background: linear-gradient(to right, orange, red); border-radius: 4px;\"></div>\n\n#### I hope you enjoyed this notebook and found the information provided useful for your learning and projects. If you have any feedback or questions, feel free to reach out or leave a comment.                                                       \n\n### Thank you for going through this notebook, and happy coding!","metadata":{}}]}